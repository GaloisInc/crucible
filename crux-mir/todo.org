* TODO

** Failing concrete test cases


-- arith
test/conc_eval/crypto/add.rs:// FAIL: needs arith trait

-- waitin on mir-json
test/conc_eval/stdlib/default.rs:// FAIL: Default trait (temporarily) not included in mir-lib

-- iterators
test/conc_eval/array/iter.rs:// FAIL: invalid slice access

-- vec and string
test/conc_eval/array/wick1.rs:// FAIL: needs Vec data structure from stdlib
test/conc_eval/array/wick3.rs:// FAIL: needs Vec data structure from stdlib
test/conc_eval/prim/lit.rs:// FAIL:  Don't know how to call ::str::{{impl}}[35]::len

-- shift
test/conc_eval/prim/shift_exceeding.rs:// FAIL: Should panic, but doesn't

-- dynamic traits, or other
test/conc_eval/traits/dynamic_branch.rs:// FAIL: dynamic trait. Also use of "::convert::From::from"
test/conc_eval/traits/dynamic_med.rs:// FAIL: dynamic trait object
test/conc_eval/traits/dynamic_poly.rs:// FAIL: needs dynamic trait object
test/conc_eval/traits/dynamic_simple.rs:// FAIL: dynamic trait object
test/conc_eval/traits/dynamic_two.rs:// FAIL: dynamic trait object

test/conc_eval/traits/gen_trait_poly.rs:// FAIL: need to construct dictionary with polymorphic member from generic instance

** Failing symbolic test cases

  Passes:
    symb_eval/crypto/double.rs
    symb_eval/crypto/ffs.rs
    symb_eval/crypto/bytes2.rs 

  Fails:
    symb_eval/crypto/bytes.rs   -- spec is wrong though. 

** test/crypto/scalar.rs status

   Failure encountered while generating a Crucible CFG: at <::std::macros::panic macros>:4:9: 
   4:72: callExp: Don't know how to call ::panicking::begin_panic<&string>

Derives from trying to translate this block:

   let mut _35 : &(&string,u32,u32);
   let mut _36 : &(&string,u32,u32);

   StorageLive(_35);
   StorageLive(_36);
   _36 = &Promoted(promoted[0]);
   _35 = use(_36);
   call(::panicking::begin_panic<&string>("assertion failed: res[i] == zero[i]"
                                         ,_35))

** Standard library current status
   Library code found in mir-lib/src/*


*** libcore prelude
   Based on implementation here, but adapted
   https://github.com/rust-lang/rust/tree/master/src/libcore

   -- pub use marker::{Copy, Send, Sized, Sync, Unpin};
   markers ignored as there isn't anything to do

   -- pub use ops::{Drop, Fn, FnMut, FnOnce};
   Drop: ignored
   Fn/FnMut/FnOnce hardwired

   -- pub use mem::drop;
   TODO  (size_of etc)

   -- pub use clone::Clone;
   DONE 

   -- pub use cmp::{PartialEq, PartialOrd, Eq, Ord};
   DONE

   -- pub use convert::{AsRef, AsMut, Into, From};
   DONE

   -- pub use default::Default;
   DONE (caveat --- macro impls)

   -- pub use iter::{Iterator, Extend, IntoIterator};
   TODO

   -- pub use iter::{DoubleEndedIterator, ExactSizeIterator};
   TODO 

   -- pub use option::Option::{self, Some, None};
   DONE (caveat -- iterators)

   -- pub use result::Result::{self, Ok, Err};
   DONE

*** ops
       DONE
    mod deref;
    mod function;
    mod index;
    mod range;
    mod try;
       TODO
    mod arith;
    mod bit;
    mod drop;
    mod generator;
    mod unsize;

*** slice
    key indexing traits from library available
    major portions missing due to lack of iterator support

*** other todos
--strings, fmt
--vec
--num
--more intrinsics:
   https://github.com/rust-lang/rust/blob/master/src/libcore/intrinsics.rs
   (Though look for the functions that wrap them, which are more stable.)
--...

** Implementation todos

- have a mode where if crucible translation fails, output "assert false". Then 
  even if we can't translate a function we can still override it.

- combine mir-lib into a single crate so can resolve circular references

- make test runner check timestamp of mir-json

- separate processing of mir-lib from that of each test file so don't have to
  reprocess the stdlib on every call

- divide Trans.hs into multiple files so that typechecking/compilation is snappier
  current 4k file overwhelms dante-mode

- better interface to symbolic evaluation.  need a rust interface
  module for examples to import and need to load the definitions in
  mir-verifier.
  In particular, should make assertions from calls to "panic" etc.

- Implementation of closures is very hacky
   -- unsafe coerce in "call"
   -- doesn't take advantage of equality constraints (FnOnce::Output)

- need more structured error handling
   don't use "error", use "fail" instead
   pretty print error messages instead of constructing strings
   distinguish "BUG" errors from limitations of the system (user facing)

- just-in time function translation using overrides?
  or some caching of the standard library?
   - see crucible-jvm

- generic trait impls has only a partial solution
  e.g.   
     impl<U> G for Data<U> where U:G { ... }

  Works in most common case, but fails when there is more than one
  constraint on U (or multiple constrained types)

- translation of Slice types isn't compositional (requires identifying outer ref)
      
  M.TyRef (M.TySlice t) M.Immut -> tyToReprCont t $ \repr -> Some (CT.VectorRepr repr)
  M.TyRef (M.TySlice t) M.Mut   -> tyToReprCont t $ \repr -> Some (MirSliceRepr repr)

  This could be problemmatic if we ever need to substitute a slice type into 
  M.TyRef (M.TyParam 0).

  Maybe this isn't an issue
  Should explore other designs

- dynamic trait invocation (i.e. trait objects) (test/conc_eval/traits/dynamic*.rs)
   + a "trait object" is a value (coerced to Any) accompanied by its
     vtable. However, we need to make a coerced version of that vtable
     so that it can take arguments of type "Any" instead of the
     implementation type.  This requires allocating a bunch of
     function handles for the wrapped vtable (one for each
     implementation type)



* Dictionary Translation notes

The goal is to eliminate trait predicates from methods by passing in
additional term arguments to the methods and to eliminate associated 
types by passing in additional type arguments 

NOTE: dictionary passing involves both a type translation and a term
translation.  We must do the type translation prior to Crucible code
generation because we need to allocate function handles with the
correct types.
It is convenient to do the term translation with code generation as
the term translation is not purely syntax-directed. We need to lookup
trait information while we do the pass.

1. Pre-passes related to dictionary translation (before code generation)
   MUST occur in this order (in transCollection)

     -- update traits, functions headers & impls to remove predicates that 
          we don't know anything about (like Sized) so that we don't 
          generate dictionaries for them
          (passRemoveUnknownPreds)
     -- update traits & function headers to include "self" predicates
          (passAddDictionaryPreds)
          TODO: also update impls?
     -- update traits with all supertrait items  
          (passExpandSuperTraits)
     -- add associated types to Fns & traits, update all substs
        to include extra arguments when they include ATs
          (passAbstractAssociated)
     -- update ADTs to include dictionary types 
         (traits must have correct types for methods at this point)
         (passAddTraitAdts)

     -- allocate method handles (MUST eliminate any uses of 
        associated types by this point)

2. The additional term arguments are "dictionaries", i.e. records of
   methods for the trait at that type
     ==> dictionary ADT decls added in prepass (see above)
     ==> mkHandleMap adds additional term args for preds when 
         handles are allocated (MirHandles remember preds)
         Q: should we do this translation in passAbstractAssociated? 
            why do we do it here?
     ==> method arguments are added during code generation
     ==> always need to know what dictionary variables are in scope
         during code generation.
         These are in the varMap, and named by trait
         we look for them in lookupFunction
         TODO: names are not unique! They should also include type
	       args for unique resolution.

3. When we create dictionaries, we need to satisfy *almost* all of the
   predicates for the members of the dictionary. This will involve
   creating additional dictionaries. And then partially applying the
   methods to those additional dictionaries. So we need to construct a
   crucible closure.
     ==> dictionary creation is done in doCall, in "normal" case
     ==> currently doesn't reuse dictionaries already in scope,
         recreates them piece by piece. Maybe that's ok.
     ==> TODO: partially apply result of lookupFunction
     ==> TODO: make sure that "recursive" dictionary is always *last*
         predicate in method impls

4. The exception is the "recursive" predicate for the dictionary
   itself. We should not partially apply those (to make the
   translation easier, otherwise we have to tie the knot
   somehow). Furthermore it is easy to provide that dictionary
   whenever we extract the method from the dictionary and call it.
     ==> this is already handled in doCall

5. Do we need to worry about other sorts of recursive dictionaries? 
   If so, how do we detect & break such loops in the translation?
   From a simple test, it looks like Rust won't allow such things. 
   i.e. we can define these impls

   impl<U> G for U where U:H {
    fn g(&self) -> Self {
        self.h()
    }
   }

   impl<U> H for U where U:G {
    fn h(&self) -> Self {
      self.g()
    }
   } 

   but these impls can't be used to satisfy any bounds.  So let's PUNT
   on this issue for now. If we get *really* paranoid we can try to
   detect it during translation to avoid infinite loops.

6. TODO: generic impl resolution. If we have an impl
   that depends on another, i.e. 

      impl<U>G for Option<U> where U:G {
           ...
      }

   we don't have a way to add this impl to the vtable. The 'TraitImpls'
   component can only store vtables for impls 
